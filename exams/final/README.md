1. What is the difference between model validation and calibration?

2. Aesthetics in data visualization refer to the visual elements that are used to encode data and represent it graphically. These elements make it easier to perceive patterns, trends, and outliers within the data. Examples:
* Color - Used to distinguish groups, highlight specific data, or represent values (e.g., heatmaps).
* Size - Points, bars, or lines can vary in size to represent different values or categories.

3. From the following color palettes the first more appropriate for effective visualization communications with humans but the second one can be used for those individual suffereing from a certain kinds of colorblindness.

4.
a. Color to distinguish categories
b. Color to represent data values (sequential)
c. Color to represent data values (diverging)
d. Color as a tool to highlight

5. The three pillars of science are: Empiricism, Theoretical Frameworks, Reproductability and Peer Review

6.  Logical implication is the logic behind whether there a physical causation or not. For example, if you lift weights you will gain muscle, but if you dont lift you wont gain muscle.
    There are some irregular cases lets say if some has a high protien diet and eats enough to sustain without lifting but for the average person.

7. asojaosdj FInish after

8. The school of probability theory that explicitly allows for the incorporation of expert (prior) knowledge in scientific inference is the Bayesian school.
   Bayesian probability theory uses Bayes' theorem to update the probability estimate for a hypothesis as more evidence or information becomes available.
   This approach starts with a prior probability, which is based on expert knowledge or previous belief before new evidence is considered.
   This prior is then updated with new data to form a posterior probability. In contrast, the frequentist school of probability does not incorporate prior knowledge in the same way.
   Frequentist methods rely on long-run frequencies of events to derive conclusions and typically use data from experiments or observed outcomes to make inferences about probabilities.
   Prior beliefs or expert knowledge are not mathematically integrated into the inference process in frequentist statistics.

9. When data is scarce, the Bayesian school of probability theory is often more useful for scientific inference compared to the frequentist approach. This is due to several key advantages:
* Incorporation of Prior Knowledge: Bayesian methods allow for the explicit use of prior knowledge through prior probabilities. This is particularly valuable when data is limited, as the prior can provide a necessary framework or context for making inferences, essentially compensating for the lack of data.
* Updating Beliefs: Bayesian inference is dynamic and allows for updating the probability estimates as new data becomes available, even if it's sparse. This feature makes it ideal for situations where data may be gathered incrementally over time.
* Probabilistic Interpretation: Bayesian statistics provide a probabilistic interpretation of results, offering probabilities for hypotheses rather than just decisions of reject or fail to reject, as in frequentist tests. This can be more informative in contexts where decisions or conclusions need to be drawn from limited data.
* Flexibility in Model Building: Bayesian methods can be more flexible in terms of model building, accommodating various types of data and complexities in modeling that can be beneficial when data is not extensive.

10. The school of thought in probability theory that cannot define or discuss the probability of the existence of God is the frequentist school. This limitation stems from the fundamental principles on which frequentist probability is based on:
* Empirical and Objective Basis: Frequentist probability defines an event's probability in terms of its long-run frequency of occurrence in repeated experiments or trials. This approach requires the ability to repeatedly observe and measure outcomes under similar conditions.
* Lack of Subjective Elements: Frequentist methods avoid the use of prior beliefs or subjective judgments in calculating probabilities. They focus solely on the data from observed events.
Given these characteristics, frequentist probability is not equipped to handle questions about the existence of entities or events that cannot be empirically tested or observed. The existence of God, being a metaphysical question that cannot be resolved through empirical data or repeated experimentation, does not fit into the framework of frequentist probability.
In contrast, Bayesian probability could theoretically assign probabilities to the existence of God, as it allows for the incorporation of subjective beliefs and prior knowledge through the use of prior probabilities. This does not mean that Bayesian probability provides a definitive answer to such metaphysical questions, but it can reflect degrees of belief based on the available information and personal or collective judgments.

11.
* Y-axis Label: The y-axis is labeled as "density" but doesn't specify what the density refers to.
* X-axis Scale: Depending on the context, the scale of the x-axis, which represents age in years, may not be appropriate.
* Possible Data Artifacts: The small bump at the start of the graph near age 0 could be a data artifact or may need explanation.
* Graphical Representation: If this is meant to be a kernel density estimate, the graph should smoothly estimate the density of points.
* Missing Context: Without additional context or explanation of what the data represents, it is challenging to interpret the graph.
* No Title: The graph lacks a title, which is essential to provide immediate context to the viewer about what is being represented.
* Zero Density at the Start and End: The density appears to reach exactly zero at the start and end of the age range, which might be an artifact of the way the density estimation is done. In reality, a kernel density plot should typically approach zero asymptotically.

12. Everything is represented by integers in computers because computers use binary (base-2) number system, where all data is encoded using only two states: 0 and 1. Integers are easily represented and manipulated in binary, making them a fundamental building block for encoding more complex data types and instructions efficiently.

13. An ancestor programming language of C is B.

14. The first high-level programming language in computer history is commonly considered to be Fortran, which stands for Formula Translation.

15, 16, 19, 21 are uploaded files

17. Name the two different categories of logical reasoning and provide and example of each class.

18. What does it mean if two Boolean propositions are equal?

20. Can we represent all real numbers in computers?









